{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1 – Setup & paths"
      ],
      "metadata": {
        "id": "Ndq_NoVoYSkx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh8AatHiW8X-",
        "outputId": "20c4ae85-1c76-4488-b4a7-dd5413e0b580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Base dir: /content/drive/MyDrive/face_liveness_rose\n",
            "Original CSV: /content/drive/MyDrive/face_liveness_rose/metadata/rose_youtu_filelist.csv\n",
            "New CSV will be: /content/drive/MyDrive/face_liveness_rose/metadata/rose_youtu_filelist_split.csv\n"
          ]
        }
      ],
      "source": [
        "# 1. Basic imports & paths (Colab style)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Base directory for your project\n",
        "base_dir = \"/content/drive/MyDrive/face_liveness_rose\"\n",
        "\n",
        "# Original CSV created by your previous pipeline\n",
        "orig_csv_path = f\"{base_dir}/metadata/rose_youtu_filelist.csv\"\n",
        "\n",
        "# New CSV with updated train/val/test split\n",
        "new_csv_path = f\"{base_dir}/metadata/rose_youtu_filelist_split.csv\"\n",
        "\n",
        "print(\"Base dir:\", base_dir)\n",
        "print(\"Original CSV:\", orig_csv_path)\n",
        "print(\"New CSV will be:\", new_csv_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 – Create new train/val/test split"
      ],
      "metadata": {
        "id": "o77-bnMxYIr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create new train / val / test split\n",
        "\n",
        "# Load original CSV\n",
        "df = pd.read_csv(orig_csv_path)\n",
        "print(\"Original split counts:\")\n",
        "print(df[\"split\"].value_counts())\n",
        "print()\n",
        "\n",
        "# Old train and old test (from your previous pipeline)\n",
        "old_train = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
        "old_test  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
        "\n",
        "print(\"Old train size:\", len(old_train))\n",
        "print(\"Old test  size:\", len(old_test))\n",
        "\n",
        "# Advisor requested sizes\n",
        "train_count = 1391\n",
        "val_count   = 350\n",
        "\n",
        "# Shuffle only the old train set\n",
        "old_train = old_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# New train and validation from old_train\n",
        "train_df = old_train.iloc[:train_count].copy()\n",
        "val_df   = old_train.iloc[train_count : train_count + val_count].copy()\n",
        "\n",
        "# Test set = old_test unchanged\n",
        "test_df  = old_test.copy()\n",
        "\n",
        "# Assign new split labels\n",
        "train_df[\"split\"] = \"train\"\n",
        "val_df[\"split\"]   = \"val\"\n",
        "test_df[\"split\"]  = \"test\"\n",
        "\n",
        "# Combine into new dataframe\n",
        "df_new = pd.concat([train_df, val_df, test_df]).reset_index(drop=True)\n",
        "\n",
        "# Save new CSV\n",
        "os.makedirs(os.path.dirname(new_csv_path), exist_ok=True)\n",
        "df_new.to_csv(new_csv_path, index=False)\n",
        "\n",
        "print(\"New split counts:\")\n",
        "print(df_new[\"split\"].value_counts())\n",
        "print(\"\\nSaved to:\", new_csv_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zv5vHGXXQkU",
        "outputId": "bafa51fd-1aab-456c-dd09-98a0cd245d09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original split counts:\n",
            "split\n",
            "test     1749\n",
            "train    1748\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Old train size: 1748\n",
            "Old test  size: 1749\n",
            "New split counts:\n",
            "split\n",
            "test     1749\n",
            "train    1391\n",
            "val       350\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Saved to: /content/drive/MyDrive/face_liveness_rose/metadata/rose_youtu_filelist_split.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 – Imports for PyTorch, OpenCV, transforms"
      ],
      "metadata": {
        "id": "2HugQTjwYLWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Torch / vision imports and transforms\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load new split CSV\n",
        "df = pd.read_csv(new_csv_path)\n",
        "print(df.head())\n",
        "print(df[\"split\"].value_counts())\n",
        "\n",
        "# ImageNet normalization (for MobileNetV3)\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Train transform (you can add augmentation later if you want)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "# Val/Test transforms (no augmentation)\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzxuBYUgXixo",
        "outputId": "6cce99bc-c28d-42a9-d186-26f671cd657a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          video_path  \\\n",
            "0  /content/drive/MyDrive/face_liveness_rose/vide...   \n",
            "1  /content/drive/MyDrive/face_liveness_rose/vide...   \n",
            "2  /content/drive/MyDrive/face_liveness_rose/vide...   \n",
            "3  /content/drive/MyDrive/face_liveness_rose/vide...   \n",
            "4  /content/drive/MyDrive/face_liveness_rose/vide...   \n",
            "\n",
            "                   filename   L   S    D   X  E  person_token  index_token  \\\n",
            "0     Mf_NT_5s_g_E_5_71.mp4  Mf  NT   5s   g  E             5           71   \n",
            "1  Vm_NT_ZTE_wg_E_2_180.mp4  Vm  NT  ZTE  wg  E             2          180   \n",
            "2   Vl_NT_ZTE_g_E_6_157.mp4  Vl  NT  ZTE   g  E             6          157   \n",
            "3     G_NT_IP_wg_E_5_40.mp4   G  NT   IP  wg  E             5           40   \n",
            "4     G_NT_HS_wg_E_9_16.mp4   G  NT   HS  wg  E             9           16   \n",
            "\n",
            "   person_id  label attack_type  split  \n",
            "0          5      0        mask  train  \n",
            "1          2      0      replay  train  \n",
            "2          6      0      replay  train  \n",
            "3          5      1     genuine  train  \n",
            "4          9      1     genuine  train  \n",
            "split\n",
            "test     1749\n",
            "train    1391\n",
            "val       350\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 – Create train/val/test dataframes"
      ],
      "metadata": {
        "id": "6Msb6duZYXvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Split dataframe into train / val / test subsets\n",
        "\n",
        "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
        "val_df   = df[df[\"split\"] == \"val\"].reset_index(drop=True)\n",
        "test_df  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
        "\n",
        "print(\"Train videos:\", len(train_df))\n",
        "print(\"Val   videos:\", len(val_df))\n",
        "print(\"Test  videos:\", len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C3AqGKwYcM_",
        "outputId": "333e6dbb-1588-426a-b8e6-c22c0c367321"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train videos: 1391\n",
            "Val   videos: 350\n",
            "Test  videos: 1749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 – Dataset class (random frame vs first frame)"
      ],
      "metadata": {
        "id": "YU3yc675Ygd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Custom Dataset: random frame for train, first frame for val/test\n",
        "\n",
        "class RoseYoutuFrameDataset(Dataset):\n",
        "    def __init__(self, df, transform=None, mode=\"train\", max_attempts=5):\n",
        "        \"\"\"\n",
        "        mode: \"train\" -> random frame\n",
        "              \"val\" or \"test\" -> first frame\n",
        "        \"\"\"\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "        self.max_attempts = max_attempts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _read_frame(self, video_path, random_frame=True):\n",
        "        \"\"\"\n",
        "        If random_frame=True -> pick a random frame.\n",
        "        Else -> always take the first frame (index 0).\n",
        "        \"\"\"\n",
        "        if not os.path.exists(video_path):\n",
        "            raise FileNotFoundError(f\"Video not found: {video_path}\")\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise IOError(f\"Could not open video: {video_path}\")\n",
        "\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        if total_frames <= 0:\n",
        "            cap.release()\n",
        "            raise ValueError(f\"No frames in video: {video_path}\")\n",
        "\n",
        "        if random_frame:\n",
        "            frame_idx = torch.randint(low=0, high=total_frames, size=(1,)).item()\n",
        "        else:\n",
        "            frame_idx = 0  # first frame\n",
        "\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "        ret, frame = cap.read()\n",
        "        cap.release()\n",
        "\n",
        "        if not ret or frame is None:\n",
        "            raise ValueError(f\"Failed to read frame {frame_idx} from {video_path}\")\n",
        "\n",
        "        # BGR -> RGB\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        img = Image.fromarray(frame)\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        video_path = row[\"video_path\"]\n",
        "        label = int(row[\"label\"])\n",
        "\n",
        "        # Decide frame selection mode\n",
        "        random_frame = (self.mode == \"train\")\n",
        "\n",
        "        # Try multiple times in case of bad frame\n",
        "        for _ in range(self.max_attempts):\n",
        "            try:\n",
        "                img = self._read_frame(video_path, random_frame=random_frame)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                last_error = e\n",
        "        else:\n",
        "            # If all attempts fail, raise last error\n",
        "            raise last_error\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "BVvKO8kvYd9B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6 – Create DataLoaders"
      ],
      "metadata": {
        "id": "5JwjjtKKYrvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Create Datasets and DataLoaders\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = RoseYoutuFrameDataset(\n",
        "    train_df, transform=train_transform, mode=\"train\"\n",
        ")\n",
        "val_dataset = RoseYoutuFrameDataset(\n",
        "    val_df, transform=eval_transform, mode=\"val\"\n",
        ")\n",
        "test_dataset = RoseYoutuFrameDataset(\n",
        "    test_df, transform=eval_transform, mode=\"test\"\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,       # shuffle for training\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,      # DO NOT shuffle validation\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,      # DO NOT shuffle test\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "len(train_loader), len(val_loader), len(test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcGyvvzdYjyW",
        "outputId": "f407d462-8da9-4d37-e8de-f4ba1812b761"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44, 11, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7 – Sanity check shapes"
      ],
      "metadata": {
        "id": "iQF1rTQsYvtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Sanity check one training batch\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "images, labels = batch\n",
        "\n",
        "print(\"Images shape:\", images.shape)   # [batch_size, 3, 224, 224]\n",
        "print(\"Labels shape:\", labels.shape)   # [batch_size]\n",
        "print(\"First 10 labels:\", labels[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PNcVEqFYtej",
        "outputId": "6f6a4fef-9d98-4805-9b8e-6c4e138fabec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images shape: torch.Size([32, 3, 224, 224])\n",
            "Labels shape: torch.Size([32])\n",
            "First 10 labels: tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8 – Load MobileNetV3-Large and modify last layer"
      ],
      "metadata": {
        "id": "9Mr23ESCYzel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Model: MobileNetV3-Large (pretrained) with 1 output\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load pretrained MobileNetV3-Large\n",
        "model = models.mobilenet_v3_large(\n",
        "    weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1\n",
        ")\n",
        "\n",
        "# Replace last classification layer with 1 output neuron\n",
        "in_features = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(in_features, 1)\n",
        "\n",
        "model = model.to(device)\n",
        "print(model.classifier)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVTsSppPYxML",
        "outputId": "c7998e35-4638-409e-9178-7b70aea35f2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 122MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=960, out_features=1280, bias=True)\n",
            "  (1): Hardswish()\n",
            "  (2): Dropout(p=0.2, inplace=True)\n",
            "  (3): Linear(in_features=1280, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9 – Loss function & optimizer"
      ],
      "metadata": {
        "id": "-KDUeGTBY3It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Loss and optimizer\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-5\n",
        ")\n"
      ],
      "metadata": {
        "id": "V7UVQTT2Y1WO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10 – Training & evaluation functions (with FAR/FRR/HTER)"
      ],
      "metadata": {
        "id": "xZRKoMTaY-j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Train one epoch & evaluate with FAR, FRR, HTER\n",
        "\n",
        "def compute_metrics(labels, preds):\n",
        "    \"\"\"\n",
        "    labels: tensor of 0/1\n",
        "    preds:  tensor of 0/1 (after threshold)\n",
        "    Returns: accuracy, FAR, FRR, HTER\n",
        "    \"\"\"\n",
        "    labels = labels.cpu()\n",
        "    preds = preds.cpu()\n",
        "\n",
        "    TP = ((preds == 1) & (labels == 1)).sum().item()\n",
        "    TN = ((preds == 0) & (labels == 0)).sum().item()\n",
        "    FP = ((preds == 1) & (labels == 0)).sum().item()\n",
        "    FN = ((preds == 0) & (labels == 1)).sum().item()\n",
        "\n",
        "    total = TP + TN + FP + FN\n",
        "    acc = (TP + TN) / total if total > 0 else 0.0\n",
        "\n",
        "    # FAR: spoof classified as real => FP / (FP + TN)\n",
        "    denom_far = FP + TN\n",
        "    FAR = FP / denom_far if denom_far > 0 else 0.0\n",
        "\n",
        "    # FRR: real classified as spoof => FN / (FN + TP)\n",
        "    denom_frr = FN + TP\n",
        "    FRR = FN / denom_frr if denom_frr > 0 else 0.0\n",
        "\n",
        "    HTER = (FAR + FRR) / 2.0\n",
        "\n",
        "    return acc, FAR, FRR, HTER\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.float().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images).squeeze(1)  # [batch]\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Predictions\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs >= 0.5).long()\n",
        "\n",
        "        all_labels.append(labels.long().cpu())\n",
        "        all_preds.append(preds.cpu())\n",
        "\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    all_preds = torch.cat(all_preds)\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc, FAR, FRR, HTER = compute_metrics(all_labels, all_preds)\n",
        "\n",
        "    return avg_loss, acc, FAR, FRR, HTER\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            outputs = model(images).squeeze(1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs >= 0.5).long()\n",
        "\n",
        "            all_labels.append(labels.long().cpu())\n",
        "            all_preds.append(preds.cpu())\n",
        "\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    all_preds = torch.cat(all_preds)\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc, FAR, FRR, HTER = compute_metrics(all_labels, all_preds)\n",
        "\n",
        "    return avg_loss, acc, FAR, FRR, HTER\n"
      ],
      "metadata": {
        "id": "UXXS4SqUY-Dr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. Main training loop (with val metrics)"
      ],
      "metadata": {
        "id": "v14JWEM-ZBz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Main training loop with \"best val loss\" checkpoint saving\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"train_FAR\": [],\n",
        "    \"train_FRR\": [],\n",
        "    \"train_HTER\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_acc\": [],\n",
        "    \"val_FAR\": [],\n",
        "    \"val_FRR\": [],\n",
        "    \"val_HTER\": [],\n",
        "}\n",
        "\n",
        "best_val_loss = float(\"inf\")   # track best (lowest) validation loss\n",
        "best_model_path = f\"{base_dir}/checkpoints/mobilenetv3_best_val_loss.pth\"\n",
        "os.makedirs(os.path.dirname(best_model_path), exist_ok=True)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # ---- TRAIN ----\n",
        "    train_loss, train_acc, train_FAR, train_FRR, train_HTER = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion, device\n",
        "    )\n",
        "\n",
        "    # ---- VALIDATION ----\n",
        "    val_loss, val_acc, val_FAR, val_FRR, val_HTER = evaluate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    # Save history\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"train_FAR\"].append(train_FAR)\n",
        "    history[\"train_FRR\"].append(train_FRR)\n",
        "    history[\"train_HTER\"].append(train_HTER)\n",
        "\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "    history[\"val_FAR\"].append(val_FAR)\n",
        "    history[\"val_FRR\"].append(val_FRR)\n",
        "    history[\"val_HTER\"].append(val_HTER)\n",
        "\n",
        "    # ---- CHECKPOINT: save best model by validation loss ----\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"  >>> New best model saved (val_loss = {val_loss:.4f})\")\n",
        "\n",
        "    # Logging\n",
        "    print(f\"Epoch {epoch}/{epochs}\")\n",
        "    print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, \"\n",
        "          f\"FAR: {train_FAR:.4f}, FRR: {train_FRR:.4f}, HTER: {train_HTER:.4f}\")\n",
        "    print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, \"\n",
        "          f\"FAR: {val_FAR:.4f}, FRR: {val_FRR:.4f}, HTER: {val_HTER:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz0OczgwZId-",
        "outputId": "1800de5a-12fd-4d68-bb2e-a26bd549b5d1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> New best model saved (val_loss = 0.0930)\n",
            "Epoch 1/10\n",
            "  Train - Loss: 0.2531, Acc: 0.9015, FAR: 0.0338, FRR: 0.2857, HTER: 0.1598\n",
            "  Val   - Loss: 0.0930, Acc: 0.9714, FAR: 0.0191, FRR: 0.0568, HTER: 0.0380\n",
            "  >>> New best model saved (val_loss = 0.0537)\n",
            "Epoch 2/10\n",
            "  Train - Loss: 0.0218, Acc: 0.9971, FAR: 0.0010, FRR: 0.0084, HTER: 0.0047\n",
            "  Val   - Loss: 0.0537, Acc: 0.9886, FAR: 0.0000, FRR: 0.0455, HTER: 0.0227\n",
            "Epoch 3/10\n",
            "  Train - Loss: 0.0091, Acc: 0.9971, FAR: 0.0019, FRR: 0.0056, HTER: 0.0038\n",
            "  Val   - Loss: 0.0884, Acc: 0.9714, FAR: 0.0000, FRR: 0.1136, HTER: 0.0568\n",
            "Epoch 4/10\n",
            "  Train - Loss: 0.0037, Acc: 1.0000, FAR: 0.0000, FRR: 0.0000, HTER: 0.0000\n",
            "  Val   - Loss: 0.0965, Acc: 0.9686, FAR: 0.0000, FRR: 0.1250, HTER: 0.0625\n",
            "  >>> New best model saved (val_loss = 0.0360)\n",
            "Epoch 5/10\n",
            "  Train - Loss: 0.0105, Acc: 0.9964, FAR: 0.0010, FRR: 0.0112, HTER: 0.0061\n",
            "  Val   - Loss: 0.0360, Acc: 0.9886, FAR: 0.0000, FRR: 0.0455, HTER: 0.0227\n",
            "Epoch 6/10\n",
            "  Train - Loss: 0.0167, Acc: 0.9942, FAR: 0.0039, FRR: 0.0112, HTER: 0.0075\n",
            "  Val   - Loss: 0.0959, Acc: 0.9714, FAR: 0.0000, FRR: 0.1136, HTER: 0.0568\n",
            "  >>> New best model saved (val_loss = 0.0359)\n",
            "Epoch 7/10\n",
            "  Train - Loss: 0.0066, Acc: 0.9986, FAR: 0.0019, FRR: 0.0000, HTER: 0.0010\n",
            "  Val   - Loss: 0.0359, Acc: 0.9857, FAR: 0.0000, FRR: 0.0568, HTER: 0.0284\n",
            "Epoch 8/10\n",
            "  Train - Loss: 0.0015, Acc: 1.0000, FAR: 0.0000, FRR: 0.0000, HTER: 0.0000\n",
            "  Val   - Loss: 0.0362, Acc: 0.9886, FAR: 0.0000, FRR: 0.0455, HTER: 0.0227\n",
            "  >>> New best model saved (val_loss = 0.0321)\n",
            "Epoch 9/10\n",
            "  Train - Loss: 0.0023, Acc: 1.0000, FAR: 0.0000, FRR: 0.0000, HTER: 0.0000\n",
            "  Val   - Loss: 0.0321, Acc: 0.9886, FAR: 0.0000, FRR: 0.0455, HTER: 0.0227\n",
            "  >>> New best model saved (val_loss = 0.0290)\n",
            "Epoch 10/10\n",
            "  Train - Loss: 0.0028, Acc: 0.9993, FAR: 0.0000, FRR: 0.0028, HTER: 0.0014\n",
            "  Val   - Loss: 0.0290, Acc: 0.9886, FAR: 0.0000, FRR: 0.0455, HTER: 0.0227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12 – Load best model and evaluate on test set"
      ],
      "metadata": {
        "id": "eeK8DLksZK67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Load best (val loss) model and evaluate on test set\n",
        "\n",
        "best_model_path = f\"{base_dir}/checkpoints/mobilenetv3_best_val_loss.pth\"\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    print(\"Loaded best model from:\", best_model_path)\n",
        "else:\n",
        "    print(\"Best model file not found, using current model weights.\")\n",
        "\n",
        "test_loss, test_acc, test_FAR, test_FRR, test_HTER = evaluate(\n",
        "    model, test_loader, criterion, device\n",
        ")\n",
        "\n",
        "print(\"\\n=== Final Test Results (Best Val Loss Model) ===\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Acc : {test_acc:.4f}\")\n",
        "print(f\"Test FAR : {test_FAR:.4f}\")\n",
        "print(f\"Test FRR : {test_FRR:.4f}\")\n",
        "print(f\"Test HTER: {test_HTER:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW10Xy6bZWBQ",
        "outputId": "4cdea9d2-6ec6-4473-c428-2e3d87893337"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded best model from: /content/drive/MyDrive/face_liveness_rose/checkpoints/mobilenetv3_best_val_loss.pth\n",
            "\n",
            "=== Final Test Results (Best Val Loss Model) ===\n",
            "Test Loss: 0.0403\n",
            "Test Acc : 0.9863\n",
            "Test FAR : 0.0000\n",
            "Test FRR : 0.0535\n",
            "Test HTER: 0.0267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13 – Save model checkpoint"
      ],
      "metadata": {
        "id": "979mxvvdZael"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Save best model\n",
        "\n",
        "checkpoint_dir = f\"{base_dir}/checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "save_path = os.path.join(checkpoint_dir, \"mobilenetv3_liveness_best_valHTER.pth\")\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print(\"Model saved to:\", save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAMewfVzZazZ",
        "outputId": "e237b833-d80b-4539-fd1c-44d4a01a1852"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/face_liveness_rose/checkpoints/mobilenetv3_liveness_best_valHTER.pth\n"
          ]
        }
      ]
    }
  ]
}